{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfe6088-ef81-439e-8df2-8320179a2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import *\n",
    "from darknet import *\n",
    "from yolo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "74af91ac-c9d1-4a09-b306-6a8787f4c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a6bc2656-0f67-4bc6-b383-d8cff254191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    '''\n",
    "    Loss function as described in https://arxiv.org/pdf/1506.02640.pdf\n",
    "    Inputs: Tensors of size [b, S, S, B * 5 + C]\n",
    "    Output: scalar loss\n",
    "    \n",
    "    More details regarding the loss function in the forward function\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.S = 7\n",
    "        self.B = 2\n",
    "        self.C = 20\n",
    "        self.N = self.B * 5 + self.C\n",
    "        \n",
    "        self.lambda_coord = 5\n",
    "        self.lambda_noobj = 0.5\n",
    "        \n",
    "    def compute_iou(self, bbox1, bbox2):\n",
    "        \"\"\" Compute the IoU (Intersection over Union) of two set of bboxes, each bbox format: [x1, y1, x2, y2].\n",
    "        Args:\n",
    "            bbox1: (Tensor) bounding bboxes, sized [N, 4].\n",
    "            bbox2: (Tensor) bounding bboxes, sized [M, 4].\n",
    "        Returns:\n",
    "            (Tensor) IoU, sized [N, M].\n",
    "        \"\"\"\n",
    "        # adapted from motokimura's github, in my implementation the bounding boxes will always have size(0) == 1\n",
    "        bbox1, bbox2 = bbox1.unsqueeze(0), bbox2.unsqueeze(0)\n",
    "        \n",
    "        N = bbox1.size(0)\n",
    "        M = bbox2.size(0)\n",
    "\n",
    "        # Compute left-top coordinate of the intersections\n",
    "        lt = torch.max(\n",
    "            bbox1[:, :2].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, :2].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        # Conpute right-bottom coordinate of the intersections\n",
    "        rb = torch.min(\n",
    "            bbox1[:, 2:].unsqueeze(1).expand(N, M, 2), # [N, 2] -> [N, 1, 2] -> [N, M, 2]\n",
    "            bbox2[:, 2:].unsqueeze(0).expand(N, M, 2)  # [M, 2] -> [1, M, 2] -> [N, M, 2]\n",
    "        )\n",
    "        # Compute area of the intersections from the coordinates\n",
    "        wh = rb - lt   # width and height of the intersection, [N, M, 2]\n",
    "        wh[wh < 0] = 0 # clip at 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1] # [N, M]\n",
    "\n",
    "        # Compute area of the bboxes\n",
    "        area1 = (bbox1[:, 2] - bbox1[:, 0]) * (bbox1[:, 3] - bbox1[:, 1]) # [N, ]\n",
    "        area2 = (bbox2[:, 2] - bbox2[:, 0]) * (bbox2[:, 3] - bbox2[:, 1]) # [M, ]\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter) # [N, ] -> [N, 1] -> [N, M]\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter) # [M, ] -> [1, M] -> [N, M]\n",
    "\n",
    "        # Compute IoU from the areas\n",
    "        union = area1 + area2 - inter # [N, M, 2]\n",
    "        iou = inter / union           # [N, M, 2]\n",
    "\n",
    "        return iou\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        '''\n",
    "        Note: Loss in each cell is only computed for the bounding box predictor that is 'responsible', i.e has the highest IOU \n",
    "              The Loss function only penalizes classification error if an object is present in that grid cell\n",
    "\n",
    "        λ_coord * Summation [0, S^2) Summation [0, B): [(x - x_hat)^2 + (y - y_hat)^2] \n",
    "            + λ_coord * Summation [0, S^2) Summation [0, B): [(sqrt(w) - sqrt(w_hat))^2 + (sqrt(h) - sqrt(h_hat))^2] \n",
    "                + Summation [0, S^2) Summation [0, B): [(C - C_hat)^2]\n",
    "                    + λ_noobj * Summation [0, S^2) Summation [0, B): [(C - C_hat)^2]\n",
    "                        + Summation [0, S^2) Summation [0, num_classes): [(p(c) - p(c_hat)^2]\n",
    "        '''\n",
    "        batch_size = pred.size(0)\n",
    "        coord_mask = target[:, :, :, 4] > 0\n",
    "        noobj_mask = target[:, :, :, 4] == 0\n",
    "        coord_mask = coord_mask.unsqueeze(-1).expand_as(target)\n",
    "        noobj_mask = noobj_mask.unsqueeze(-1).expand_as(target)\n",
    "\n",
    "        coord_pred = pred[coord_mask].view(-1, self.N)\n",
    "        coord_target = target[coord_mask].view(-1, self.N)\n",
    "        \n",
    "        coord_pred = coord_pred[:, :10].view(-1, self.B, 5)\n",
    "        coord_target = coord_target[:, :10].view(-1, self.B, 5)\n",
    "        \n",
    "        # add some assertions i.e coord_pred.size(0) cannot be greater than batch_size * self.S ** 2\n",
    "        noobj_pred = pred[noobj_mask].view(-1, self.N)\n",
    "        noobj_target = target[noobj_mask].view(-1, self.N)\n",
    "        \n",
    "        noobj_pred = noobj_pred[:, :10].view(-1, self.B, 5)\n",
    "        noobj_target = noobj_target[:, :10].view(-1, self.B, 5)\n",
    "\n",
    "        coord_class_prob_pred = coord_pred[:, 10:]\n",
    "        coord_class_prob_target = coord_target[:, 10:]\n",
    "\n",
    "        # loss for lines 1 - 3\n",
    "        bbox_loss = 0\n",
    "        for i in range(min(self.S ** 2, coord_pred.size(0))): # only calculate bounding box loss for cells with objects\n",
    "            info = torch.empty((2, 4)) # use to determine the predictor bounding box\n",
    "\n",
    "            for j in range(self.B):\n",
    "                # rescale normalized bounding boxes for the image\n",
    "                coord_pred[i, j, :2] = coord_pred[i, j, :2] / float(self.S) - 0.5 * coord_pred[i, j, 2:4]\n",
    "                coord_pred[i, j, 2:4] = coord_pred[i, j, :2] / float(self.S) + 0.5 * coord_pred[i, j, 2:4]\n",
    "\n",
    "                coord_target[i, j, :2] = coord_target[i, j, :2] / float(self.S) - 0.5 * coord_target[i, j, 2:4]\n",
    "                coord_target[i, j, 2:4] = coord_target[i, j, :2] / float(self.S) + 0.5 * coord_target[i, j, 2:4]\n",
    "\n",
    "                l1 = self.lambda_coord * (coord_target[i, j, 0] - coord_pred[i, j, 0]) ** 2 + (coord_target[i, j, 1] - coord_pred[i, j, 1]) ** 2\n",
    "                l2 = self.lambda_coord * (coord_target[i, j, 2] ** 0.5 - coord_pred[i, j, 2] ** 0.5) ** 2 + (coord_target[i, j, 3] ** 0.5 - coord_pred[i, j, 3] ** 0.5) ** 2\n",
    "                l3 = (coord_target[i, j, 4] - coord_pred[i, j, 4]) ** 2\n",
    "\n",
    "                iou = self.compute_iou(coord_pred[i, j, :4], coord_target[i, j, :4])\n",
    "                \n",
    "                info[j, 0], info[j, 1], info[j, 2], info[j, 3] = l1, l2, l3, iou\n",
    "\n",
    "            bbox_loss += sum(info[info[:, 3].argmax()])\n",
    "\n",
    "        # loss for line 4\n",
    "        noobj_loss = self.lambda_noobj * F.mse_loss(noobj_pred[:, :, 4], noobj_target[:, :, 4], reduction='sum')\n",
    "        \n",
    "        # loss for line 5\n",
    "        class_prob_loss = F.mse_loss(coord_class_prob_pred, coord_class_prob_target, reduction='sum')\n",
    "        \n",
    "        total_loss = bbox_loss + noobj_loss + class_prob_loss\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "689794fe-d9cd-4861-add1-32c4bbe3abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "61446c02-08c8-4034-bc92-b3e096c5d916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19.0468)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(torch.rand(1, 7, 7, 30), torch.zeros(1, 7, 7, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "6f3ca73b-b0a9-433b-a898-57502d68012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = nn.MaxPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "55a37939-4691-4dfc-ac11-f24843b42c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = torch.rand(1, 3, 54, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "bf56170c-44e9-43f9-b70a-b80c8076d709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 27, 27])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp(layer).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "5b15b088-8b92-49c3-b728-f84c96d8edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Darknet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # network blocks are built in the same fashion as Figure 3 (https://arxiv.org/pdf/1506.02640.pdf)\n",
    "        # last 4 conv layers belong to YOLO\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            # repeat these 2 layers 4 times\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.block5 = nn.Sequential(\n",
    "            # repeat these 2 layers 2 times\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AvgPool2d(7),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 1000)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Inputs: Tensor of shape [b, 3, 224, 224]\n",
    "        Outputs: Tensor of shape [b, 1000]\n",
    "        '''\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "eb721367-936e-4895-b77d-ff2dc4828f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1(nn.Module):\n",
    "    def __init__(self, grid_size, num_bboxes, num_classes):\n",
    "        super().__init__()\n",
    "        self.S = grid_size\n",
    "        self.B = num_bboxes\n",
    "        self.C = num_classes\n",
    "        \n",
    "        self.darknet = Darknet()\n",
    "        self.darknet.fc = nn.Identity() # remove fc layer\n",
    "        \n",
    "        # YOLO has 4 additional convolutional layers\n",
    "        self.relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7 * 7 * 1024, 4096),\n",
    "            nn.LeakyReLU(0.1, inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, self.S * self.S * (self.B * 5 + self.C)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x)\n",
    "        x = self.relu(self.bn(self.conv1(x)))\n",
    "        x = self.relu(self.bn(self.conv2(x)))\n",
    "        x = self.relu(self.bn(self.conv3(x)))\n",
    "        x = self.relu(self.bn(self.conv4(x)))\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        x = x.view(-1, self.S, self.S, self.B * 5 + self.C)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b7b41af8-b768-4f75-b238-b261ee2d0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "406bf959-09ed-4fd2-b8aa-06131f49099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5e86704b-9099-4706-9cf5-43edc4d96d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = Darknet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "d56108ab-363c-429f-b1e1-47d3c61d9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b10c80f2-88da-474e-a833-57e03642350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = torch.rand(10, 3, 448, 448)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "26a4f98a-43bf-4442-b61f-78d2cf5a8077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1024, 14, 14])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dn(lol).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "d821148d-c543-459c-99f0-234d27802bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo = YOLOv1(7, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2ce6776f-d0ea-43e2-8750-eff8124aec58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 7, 7, 30])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo(lol).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b3990d-4d3b-4610-9817-d8c2799c876f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.empty((2, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a1a27-71fa-4f7d-ac60-8652ce910c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "afc6f26a-3396-441f-b302-29fb93affb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.67492429e-310, 0.00000000e+000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.empty((2, 4))[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "245ed7f8-dc66-4271-bf8f-d1ecd77f17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = torch.empty((2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7cad41a-f755-43e9-81ef-b63117a7b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes[0] = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0294267-a581-41b3-b75a-f07ec0868b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 2.0000e+00, 3.0000e+00, 4.0000e+00],\n",
       "        [1.1210e-43, 0.0000e+00, 1.1210e-43, 0.0000e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d38a7da3-0d1c-490e-8641-c8312192fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yes[yes[:, 3].argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aca8af9c-5be1-4e87-8593-cf8a18bed04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = torch.rand(3, 7, 7, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b186237-2229-41c8-a656-b563587fd906",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_mask = ex[:, :, :, 4] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc79f7b-7d36-4dc6-b6b8-1fb8b89482b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_mask = coord_mask.unsqueeze(-1).expand_as(ex) # [b, s, s, n], expands True/False along the last dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "188f5c12-8cd7-4fbf-a16b-0c24f94e9fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex[coord_mask].view(-1, 30).shape # pred tensor on which cells contain objects (cannot exceed batch_size * 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39e17b3b-7809-473f-bc8f-2d71f89a29c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 2, 30]' is invalid for input of size 4410",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coord_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcoord_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 2, 30]' is invalid for input of size 4410"
     ]
    }
   ],
   "source": [
    "coord_tensor = ex[coord_mask].view(-1, 2, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4365c72c-7121-4a88-ab8a-5e8a66d8bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147, 30])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2d3c266-f21d-466e-9f0d-969c436cd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pred = coord_tensor[:, :10].contiguous().view(-1, 5) # rearrange predictions where each row is [x, y, w, h, c]\n",
    "# cannot exceed 2 * batch_size * 49 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5c5bacb-85d1-4665-b0f6-479a910e1d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3103, 0.9990, 0.1813,  ..., 0.7750, 0.3578, 0.6521],\n",
       "        [0.9908, 0.9281, 0.1904,  ..., 0.9622, 0.6246, 0.7205],\n",
       "        [0.1489, 0.4374, 0.6778,  ..., 0.8772, 0.5053, 0.9776],\n",
       "        ...,\n",
       "        [0.0501, 0.0574, 0.5785,  ..., 0.8874, 0.0271, 0.4839],\n",
       "        [0.6005, 0.1547, 0.7346,  ..., 0.3301, 0.9680, 0.7063],\n",
       "        [0.1751, 0.0064, 0.5625,  ..., 0.8553, 0.5265, 0.6781]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_tensor[:, 10:].contiguous().view(-1, 20) # rearrange predictions where each row in [p1, p2, p3] class-prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07fda3fd-4a62-4dd2-afc2-7c0d8cda836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_pred2 = coord_tensor[:, :10].view(-1, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2f5c3a2-fbc1-4ced-b9fb-9f97da101cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6695, 0.1184, 0.5340, 0.7720, 0.6951],\n",
       "         [0.6203, 0.8119, 0.5678, 0.2015, 0.2547]],\n",
       "\n",
       "        [[0.1451, 0.3023, 0.4500, 0.5360, 0.1922],\n",
       "         [0.0606, 0.0996, 0.5777, 0.0309, 0.5509]],\n",
       "\n",
       "        [[0.1015, 0.2533, 0.8717, 0.7552, 0.0876],\n",
       "         [0.8835, 0.9294, 0.2872, 0.3540, 0.7213]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0428, 0.8953, 0.1482, 0.1101, 0.5496],\n",
       "         [0.6678, 0.4397, 0.7340, 0.3082, 0.7076]],\n",
       "\n",
       "        [[0.9469, 0.4161, 0.4693, 0.8817, 0.6018],\n",
       "         [0.5183, 0.3621, 0.7801, 0.5793, 0.9798]],\n",
       "\n",
       "        [[0.1479, 0.5408, 0.7987, 0.7272, 0.4864],\n",
       "         [0.2645, 0.1258, 0.9490, 0.3677, 0.2526]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8dffe9cf-2d7f-4dbe-ac11-acab40df42d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6695, 0.1184, 0.5340, 0.7720, 0.6951],\n",
       "        [0.6203, 0.8119, 0.5678, 0.2015, 0.2547],\n",
       "        [0.1451, 0.3023, 0.4500, 0.5360, 0.1922],\n",
       "        ...,\n",
       "        [0.5183, 0.3621, 0.7801, 0.5793, 0.9798],\n",
       "        [0.1479, 0.5408, 0.7987, 0.7272, 0.4864],\n",
       "        [0.2645, 0.1258, 0.9490, 0.3677, 0.2526]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd9576a5-f623-40d6-b3d1-63a917bfcd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([294, 5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b311441-8688-4078-8c32-66dd29b70b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6695, 0.1184, 0.5340, 0.7720, 0.6951],\n",
       "        [0.6203, 0.8119, 0.5678, 0.2015, 0.2547]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_pred[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be144668-aee5-4e3e-9145-5515468e229a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cd55eb-a1b3-498e-bcea-cf0e3a1e1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bbox_pred\n",
    "class_pred\n",
    "\n",
    "bbox_target\n",
    "class_target\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8882fb-db2b-409d-81e6-bbfac721328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
